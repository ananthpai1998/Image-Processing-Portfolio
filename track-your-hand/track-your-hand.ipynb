{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  # OpenCV library for image/video processing\n",
    "import mediapipe as mp  # MediaPipe library for machine learning-based hand detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe's Hands module and Drawing utilities\n",
    "mp_hands = mp.solutions.hands  # Import the hands module from MediaPipe solutions for hand detection\n",
    "mp_drawing = mp.solutions.drawing_utils  # Import drawing utilities from MediaPipe to visualize detected hand landmarks\n",
    "\n",
    "# Create an instance of the Hands class with configurations\n",
    "# - max_num_hands: Maximum number of hands to detect (2 hands)\n",
    "# - min_detection_confidence: Minimum confidence score for hand detection (0.7)\n",
    "hands = mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.7)\n",
    "\n",
    "# Open a connection to the default camera (camera index 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Main loop to continuously capture frames and perform hand detection\n",
    "while cap.isOpened():  # While the camera feed is open and capturing\n",
    "    ret, frame = cap.read()  # Capture a frame from the camera\n",
    "    if not ret:  # Check if the frame is captured correctly; if not, exit the loop\n",
    "        break\n",
    "    \n",
    "    # Convert the captured frame from BGR color space (OpenCV default) to RGB color space\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process the RGB frame through the MediaPipe Hands model to detect hand landmarks\n",
    "    result = hands.process(rgb_frame)\n",
    "    \n",
    "    # Check if any hand landmarks are detected in the frame\n",
    "    if result.multi_hand_landmarks:\n",
    "        # Loop through each detected hand's landmarks\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            # Draw the detected hand landmarks and connections on the original frame (in BGR format)\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "    \n",
    "    # Display the frame with the detected hand landmarks in a window titled \"Hand Detection\"\n",
    "    cv2.imshow(\"Hand Detection\", frame)\n",
    "    \n",
    "    # Wait for a key press, and if the 'q' key is pressed, exit the loop\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the camera resource when done\n",
    "cap.release()\n",
    "\n",
    "# Close all OpenCV windows that were opened during the program\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-env",
   "language": "python",
   "name": "gpu-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
